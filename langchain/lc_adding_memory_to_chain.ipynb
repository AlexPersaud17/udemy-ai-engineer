{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007b7b0e-530d-4a18-8e25-0033f1b7cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112357dd-e0c1-4295-a93b-0b464c22097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ebe266-e773-40df-945a-f8c972b7282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "{message_log}\n",
    "\n",
    "Human: \n",
    "{question}\n",
    "\n",
    "AI:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811653cb-ce9f-431a-956e-a6989e67b661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4o-mini', \n",
    "                  seed = 365,\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7525247f-a5ac-41b3-9e6e-f04949da2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/ly3y_3m57537dkrh09vsr_mw0000gn/T/ipykernel_87784/3002585002.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(),\n"
     ]
    }
   ],
   "source": [
    "chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(),\n",
    "                                        memory_key=\"message_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17fbbe7e-1822-4a50-872d-fa899a531466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"Can you give me an interesting fact I probably didn't know about?\"\n",
    "question = \"Can you elaborate a bit more on this fact?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eefbb4a3-e33b-49ce-b9bb-07395ce40da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_output = RunnablePassthrough.assign(message_log=RunnableLambda(chat_memory.load_memory_variables) |\n",
    "                          itemgetter('message_log')).invoke({'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e64995d3-6b85-407f-80a0-6cbbbd5f0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value_output = prompt_template.invoke(dictionary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d23508e-cb06-4b20-97e0-32ec61a56048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message_output=chat.invoke(prompt_value_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5feab26a-438d-4a1c-b8ae-ec9cfae0e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = StrOutputParser().invoke(ai_message_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1029c64-2301-4bcc-aa69-e0476f5ea277",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory.save_context(inputs = {'inputs':question},\n",
    "                         outputs = {'outputs':response}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b69422f-eb85-42db-b899-ee4fa9f39fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': \"The human asks the AI for an interesting fact they probably didn't know about, and the AI shares that honey never spoils because of its low moisture content and acidic pH. The human then asks the AI to elaborate, and the AI explains that honey's longevity is due to its unique chemical composition, low moisture content, and acidic pH levels. Bees create honey by collecting nectar from flowers and enzymatically transforming it into the sweet substance we know.\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4aeb76b8-9137-40c1-89c6-b71d5f578e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Absolutely! Honey's remarkable longevity is primarily due to its unique chemical composition. It has a low moisture content, typically around 17-18%, which is not enough to support the growth of most bacteria and fungi. Additionally, honey is naturally acidic, with a pH level ranging from about 3.2 to 4.5. This acidity further inhibits microbial growth.\\n\\nAnother fascinating aspect of honey is the process by which bees create it. Bees collect nectar from flowers and then enzymatically convert it\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1 = (\n",
    "    RunnablePassthrough.assign(\n",
    "        message_log = RunnableLambda(chat_memory.load_memory_variables) | \n",
    "        itemgetter('message_log')) \n",
    "    | prompt_template \n",
    "    | chat \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# question = \"Can you give me an interesting fact I probably didn't know about?\"\n",
    "question = \"Can you elaborate a bit more on this fact?\"\n",
    "\n",
    "response = chain1.invoke({'question':question})\n",
    "\n",
    "chat_memory.save_context(inputs = {'input':question}, \n",
    "                         outputs = {'output':response})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f13513-415e-4a44-91e1-6bafb2f5fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def memory_chain(question):\n",
    "    \n",
    "    chain1 = (\n",
    "        RunnablePassthrough.assign(\n",
    "            message_log = RunnableLambda(chat_memory.load_memory_variables) | \n",
    "            itemgetter('message_log')) \n",
    "        | prompt_template \n",
    "        | chat \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    response = chain1.invoke({'question':question})\n",
    "\n",
    "    chat_memory.save_context(inputs = {'input':question}, \n",
    "                             outputs = {'output':response})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d2fd130-3837-4599-9ba0-f152d89a4002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Absolutely! Honey's remarkable longevity is primarily due to its unique chemical composition. The low moisture content in honey, typically around 17-18%, creates an environment that is inhospitable for bacteria and other microorganisms. Additionally, honey has a natural acidity, with a pH level ranging from about 3.2 to 4.5, which further prevents the growth of harmful organisms.\\n\\nAnother fascinating aspect is that honey contains hydrogen peroxide, which is produced when the enzyme glucose oxidase breaks down glucose\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_chain.invoke(\"Can you elaborate a bit more on this fact?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b0cbbd-55e0-4085-aabb-5a71114c480b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
